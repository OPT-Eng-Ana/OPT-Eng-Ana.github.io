@article{gregor2015draw,
  title={DRAW: A recurrent neural network for image generation},
  author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
  journal={arXiv preprint, arXiv:1502.04623},
  year={2015},
  url={https://arxiv.org/pdf/1502.04623.pdf}
}

@inproceedings{zhang2021complexity,
  title={The complexity of nonconvex-strongly-concave minimax optimization},
  author={Zhang, Siqi and Yang, Junchi and Guzm{\'a}n, Crist{\'o}bal and Kiyavash, Negar and He, Niao},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={482--492},
  year={2021},
  organization={PMLR},
  url={https://proceedings.mlr.press/v161/zhang21c.html}
}

@book{nesterov2018lectures,
  title={Lectures on convex optimization},
  author={Nesterov, Yurii and others},
  volume={137},
  year={2018},
  publisher={Springer},
  url={https://link.springer.com/book/10.1007/978-3-319-91578-4}
}

@article{bubeck2015convex,
  title={Convex optimization: Algorithms and complexity},
  author={Bubeck, S{\'e}bastien and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={8},
  number={3-4},
  pages={231--357},
  year={2015},
  publisher={Now Publishers, Inc.},
  url={https://arxiv.org/abs/1405.4980}
}

@book{blair1985problem,
	author = {Nemirovski, Arkadi. S. and  Yudin, David. B.},
	title = {{Problem Complexity and Method Efficiency in Optimization}},
	publisher = {Wiley, New York},
	year = {1983}
}

@article{carmon2021lower,
  title={Lower bounds for finding stationary points II: first-order methods},
  author={Carmon, Yair and Duchi, John C and Hinder, Oliver and Sidford, Aaron},
  journal={Mathematical Programming},
  volume={185},
  number={1},
  pages={315--355},
  year={2021},
  publisher={Springer},
  url={https://link.springer.com/article/10.1007/s10107-019-01431-x}
}
@article{carmon2020lower,
  title={Lower bounds for finding stationary points I},
  author={Carmon, Yair and Duchi, John C and Hinder, Oliver and Sidford, Aaron},
  journal={Mathematical Programming},
  volume={184},
  number={1},
  pages={71--120},
  year={2020},
  publisher={Springer},
  url={https://link.springer.com/article/10.1007/s10107-019-01406-y}
}

@article{davis2018stochastic,
  title={Stochastic subgradient method converges at the rate $ O (k^{-1/4}) $ on weakly convex functions},
  author={Davis, Damek and Drusvyatskiy, Dmitriy},
  journal={arXiv preprint arXiv:1802.02988},
  year={2018},
  url={https://arxiv.org/abs/1802.02988}
}

@article{defazio2016simple,
  title={A simple practical accelerated method for finite sums},
  author={Defazio, Aaron},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016},
  url={https://proceedings.neurips.cc/paper_files/paper/2016/hash/4f6ffe13a5d75b2d6a3923922b3922e5-Abstract.html}
}

@article{allen2018katyusha,
  title={Katyusha: The first direct acceleration of stochastic gradient methods},
  author={Allen-Zhu, Zeyuan},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={221},
  pages={1--51},
  year={2018},
  url={https://www.jmlr.org/papers/v18/16-410.html}
}

@article{woodworth2016tight,
  title={Tight complexity bounds for optimizing composite objectives},
  author={Woodworth, Blake E and Srebro, Nati},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016},
  url={https://proceedings.neurips.cc/paper/2016/hash/645098b086d2f9e1e0e939c27f9f2d6f-Abstract.html}
}

