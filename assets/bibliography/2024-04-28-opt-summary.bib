@book{nesterov2018lectures,
  title={Lectures on convex optimization},
  author={Nesterov, Yurii and others},
  volume={137},
  year={2018},
  publisher={Springer},
  url={https://link.springer.com/book/10.1007/978-3-319-91578-4}
}

@article{bubeck2015convex,
  title={Convex optimization: Algorithms and complexity},
  author={Bubeck, S{\'e}bastien and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={8},
  number={3-4},
  pages={231--357},
  year={2015},
  publisher={Now Publishers, Inc.},
  url={https://arxiv.org/abs/1405.4980}
}

@book{blair1985problem,
	author = {Nemirovski, Arkadi. S. and  Yudin, David. B.},
	title = {{Problem Complexity and Method Efficiency in Optimization}},
	publisher = {Wiley, New York},
	year = {1983}
}

@article{carmon2021lower,
  title={Lower bounds for finding stationary points II: first-order methods},
  author={Carmon, Yair and Duchi, John C and Hinder, Oliver and Sidford, Aaron},
  journal={Mathematical Programming},
  volume={185},
  number={1},
  pages={315--355},
  year={2021},
  publisher={Springer},
  url={https://link.springer.com/article/10.1007/s10107-019-01431-x}
}
@article{carmon2020lower,
  title={Lower bounds for finding stationary points I},
  author={Carmon, Yair and Duchi, John C and Hinder, Oliver and Sidford, Aaron},
  journal={Mathematical Programming},
  volume={184},
  number={1},
  pages={71--120},
  year={2020},
  publisher={Springer},
  url={https://link.springer.com/article/10.1007/s10107-019-01406-y}
}

@article{davis2018stochastic,
  title={Stochastic subgradient method converges at the rate $ O (k^{-1/4}) $ on weakly convex functions},
  author={Davis, Damek and Drusvyatskiy, Dmitriy},
  journal={arXiv preprint arXiv:1802.02988},
  year={2018},
  url={https://arxiv.org/abs/1802.02988}
}

@article{defazio2016simple,
  title={A simple practical accelerated method for finite sums},
  author={Defazio, Aaron},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016},
  url={https://proceedings.neurips.cc/paper_files/paper/2016/hash/4f6ffe13a5d75b2d6a3923922b3922e5-Abstract.html}
}

@article{allen2018katyusha,
  title={Katyusha: The first direct acceleration of stochastic gradient methods},
  author={Allen-Zhu, Zeyuan},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={221},
  pages={1--51},
  year={2018},
  url={https://www.jmlr.org/papers/v18/16-410.html}
}

@article{woodworth2016tight,
  title={Tight complexity bounds for optimizing composite objectives},
  author={Woodworth, Blake E and Srebro, Nati},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016},
  url={https://proceedings.neurips.cc/paper/2016/hash/645098b086d2f9e1e0e939c27f9f2d6f-Abstract.html}
}

@inproceedings{allen2018katyusha,
  title={Katyusha x: Simple momentum method for stochastic sum-of-nonconvex optimization},
  author={Allen-Zhu, Zeyuan},
  booktitle={International Conference on Machine Learning},
  pages={179--185},
  year={2018},
  organization={PMLR},
  url={https://proceedings.mlr.press/v80/allen-zhu18a.html}
}

@article{xie2019general,
  title={A general analysis framework of lower complexity bounds for finite-sum optimization},
  author={Xie, Guangzeng and Luo, Luo and Zhang, Zhihua},
  journal={arXiv preprint arXiv:1908.08394},
  year={2019},
  url={https://arxiv.org/abs/1908.08394}
}

@inproceedings{zhou2019lower,
  title={Lower bounds for smooth nonconvex finite-sum optimization},
  author={Zhou, Dongruo and Gu, Quanquan},
  booktitle={International Conference on Machine Learning},
  pages={7574--7583},
  year={2019},
  organization={PMLR},
  url={https://proceedings.mlr.press/v97/zhou19b.html}
}

@article{wang2019spiderboost,
  title={Spiderboost and momentum: Faster variance reduction algorithms},
  author={Wang, Zhe and Ji, Kaiyi and Zhou, Yi and Liang, Yingbin and Tarokh, Vahid},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019},
  url={https://proceedings.neurips.cc/paper/2019/hash/512c5cad6c37edb98ae91c8a76c3a291-Abstract.html}
}

@article{fang2018spider,
  title={Spider: Near-optimal non-convex optimization via stochastic path-integrated differential estimator},
  author={Fang, Cong and Li, Chris Junchi and Lin, Zhouchen and Zhang, Tong},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018},
  url={https://proceedings.neurips.cc/paper_files/paper/2018/hash/1543843a4723ed2ab08e18053ae6dc5b-Abstract.html}
}

@article{ghadimi2012optimal,
  title={Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization i: A generic algorithmic framework},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={SIAM Journal on Optimization},
  volume={22},
  number={4},
  pages={1469--1492},
  year={2012},
  publisher={SIAM},
  url={https://epubs.siam.org/doi/abs/10.1137/110848864}
}

@inproceedings{rakhlin2012making,
  title={Making gradient descent optimal for strongly convex stochastic optimization},
  author={Rakhlin, Alexander and Shamir, Ohad and Sridharan, Karthik},
  booktitle={Proceedings of the 29th International Coference on International Conference on Machine Learning},
  pages={1571--1578},
  year={2012},
  url={https://icml.cc/2012/papers/261.pdf}
}

@article{lan2012optimal,
  title={An optimal method for stochastic composite optimization},
  author={Lan, Guanghui},
  journal={Mathematical Programming},
  volume={133},
  number={1},
  pages={365--397},
  year={2012},
  publisher={Springer},
  url={https://link.springer.com/article/10.1007/s10107-010-0434-y}
}

@article{woodworth2018graph,
  title={Graph oracle models, lower bounds, and gaps for parallel stochastic optimization},
  author={Woodworth, Blake E and Wang, Jialei and Smith, Adam and McMahan, Brendan and Srebro, Nati},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018},
  url={https://proceedings.neurips.cc/paper_files/paper/2018/hash/3ec27c2cff04bc5fd2586ca36c62044e-Abstract.html}
}

@article{hazan2014beyond,
  title={Beyond the regret minimization barrier: optimal algorithms for stochastic strongly-convex optimization},
  author={Hazan, Elad and Kale, Satyen},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={2489--2512},
  year={2014},
  url={https://www.jmlr.org/papers/volume15/hazan14a/hazan14a.pdf}
}

@article{nemirovski2009robust,
  title={Robust stochastic approximation approach to stochastic programming},
  author={Nemirovski, Arkadi and Juditsky, Anatoli and Lan, Guanghui and Shapiro, Alexander},
  journal={SIAM Journal on optimization},
  volume={19},
  number={4},
  pages={1574--1609},
  year={2009},
  publisher={SIAM},
  url={https://epubs.siam.org/doi/abs/10.1137/070704277}
}

@article{agarwal2009information,
  title={Information-theoretic lower bounds on the oracle complexity of convex optimization},
  author={Agarwal, Alekh and Wainwright, Martin J and Bartlett, Peter and Ravikumar, Pradeep},
  journal={Advances in Neural Information Processing Systems},
  volume={22},
  year={2009},
  url={https://proceedings.neurips.cc/paper/2009/hash/2387337ba1e0b0249ba90f55b2ba2521-Abstract.html}
}

@inproceedings{foster2019complexity,
  title={The complexity of making the gradient small in stochastic convex optimization},
  author={Foster, Dylan J and Sekhari, Ayush and Shamir, Ohad and Srebro, Nathan and Sridharan, Karthik and Woodworth, Blake},
  booktitle={Conference on Learning Theory},
  pages={1319--1345},
  year={2019},
  organization={PMLR},
  url={https://proceedings.mlr.press/v99/foster19b.html}
}

@article{ghadimi2013stochastic,
  title={Stochastic first-and zeroth-order methods for nonconvex stochastic programming},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={SIAM journal on optimization},
  volume={23},
  number={4},
  pages={2341--2368},
  year={2013},
  publisher={SIAM},
  url={https://epubs.siam.org/doi/abs/10.1137/120880811}
}

@article{arjevani2023lower,
  title={Lower bounds for non-convex stochastic optimization},
  author={Arjevani, Yossi and Carmon, Yair and Duchi, John C and Foster, Dylan J and Srebro, Nathan and Woodworth, Blake},
  journal={Mathematical Programming},
  volume={199},
  number={1},
  pages={165--214},
  year={2023},
  publisher={Springer},
  url={https://link.springer.com/article/10.1007/s10107-022-01822-7}
}

@article{chambolle2011first,
  title={A first-order primal-dual algorithm for convex problems with applications to imaging},
  author={Chambolle, Antonin and Pock, Thomas},
  journal={Journal of mathematical imaging and vision},
  volume={40},
  pages={120--145},
  year={2011},
  publisher={Springer},
  url={https://link.springer.com/article/10.1007/s10851-010-0251-1}
}

@article{ouyang2021lower,
  title={Lower complexity bounds of first-order methods for convex-concave bilinear saddle-point problems},
  author={Ouyang, Yuyuan and Xu, Yangyang},
  journal={Mathematical Programming},
  volume={185},
  number={1},
  pages={1--35},
  year={2021},
  publisher={Springer},
  url={https://link.springer.com/article/10.1007/s10107-019-01420-0}
}

@article{nemirovski2004prox,
  title={Prox-method with rate of convergence O (1/t) for variational inequalities with Lipschitz continuous monotone operators and smooth convex-concave saddle point problems},
  author={Nemirovski, Arkadi},
  journal={SIAM Journal on Optimization},
  volume={15},
  number={1},
  pages={229--251},
  year={2004},
  publisher={SIAM},
  url={https://epubs.siam.org/doi/abs/10.1137/S1052623403425629}
}

@article{mokhtari2020convergence,
  title={Convergence rate of O(1/k) for optimistic gradient and extragradient methods in smooth convex-concave saddle point problems},
  author={Mokhtari, Aryan and Ozdaglar, Asuman E and Pattathil, Sarath},
  journal={SIAM Journal on Optimization},
  volume={30},
  number={4},
  pages={3230--3251},
  year={2020},
  publisher={SIAM},
  url={https://epubs.siam.org/doi/abs/10.1137/19M127375X}
}

@inproceedings{xie2020lower,
  title={Lower complexity bounds for finite-sum convex-concave minimax optimization problems},
  author={Xie, Guangzeng and Luo, Luo and Lian, Yijiang and Zhang, Zhihua},
  booktitle={International Conference on Machine Learning},
  pages={10504--10513},
  year={2020},
  organization={PMLR},
  url={https://proceedings.mlr.press/v119/xie20d.html}
}

@article{yang2020catalyst,
  title={A catalyst framework for minimax optimization},
  author={Yang, Junchi and Zhang, Siqi and Kiyavash, Negar and He, Niao},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5667--5678},
  year={2020},
  url={https://proceedings.neurips.cc/paper/2020/hash/3db54f5573cd617a0112d35dd1e6b1ef-Abstract.html}
}

@inproceedings{du2019linear,
  title={Linear convergence of the primal-dual gradient method for convex-concave saddle point problems without strong convexity},
  author={Du, Simon S and Hu, Wei},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={196--205},
  year={2019},
  organization={PMLR},
  url={https://proceedings.mlr.press/v89/du19b.html}
}

@article{chambolle2016ergodic,
  title={On the ergodic convergence rates of a first-order primal--dual algorithm},
  author={Chambolle, Antonin and Pock, Thomas},
  journal={Mathematical Programming},
  volume={159},
  number={1},
  pages={253--287},
  year={2016},
  publisher={Springer},
  url={https://link.springer.com/article/10.1007/s10107-015-0957-3}
}

@article{zhang2022lower,
  title={On lower iteration complexity bounds for the convex concave saddle point problems},
  author={Zhang, Junyu and Hong, Mingyi and Zhang, Shuzhong},
  journal={Mathematical Programming},
  volume={194},
  number={1},
  pages={901--935},
  year={2022},
  publisher={Springer},
  url={https://link.springer.com/article/10.1007/s10107-021-01660-z}
}

@article{wang2020improved,
  title={Improved algorithms for convex-concave minimax optimization},
  author={Wang, Yuanhao and Li, Jian},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={4800--4810},
  year={2020},
  url={https://proceedings.neurips.cc/paper/2020/hash/331316d4efb44682092a006307b9ae3a-Abstract.html}
}

@inproceedings{liang2019interaction,
  title={Interaction matters: A note on non-asymptotic local convergence of generative adversarial networks},
  author={Liang, Tengyuan and Stokes, James},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={907--915},
  year={2019},
  organization={PMLR},
  url={https://proceedings.mlr.press/v89/liang19b.html}
}

@inproceedings{ibrahim2020linear,
  title={Linear lower bounds and conditioning of differentiable games},
  author={Ibrahim, Adam and Azizian, Wa{\i}ss and Gidel, Gauthier and Mitliagkas, Ioannis},
  booktitle={International conference on machine learning},
  pages={4583--4593},
  year={2020},
  organization={PMLR},
  url={https://proceedings.mlr.press/v119/ibrahim20a.html}
}

@article{arjevani2016lower,
  title={On lower and upper bounds in smooth and strongly convex optimization},
  author={Arjevani, Yossi and Shalev-Shwartz, Shai and Shamir, Ohad},
  journal={Journal of Machine Learning Research},
  volume={17},
  number={126},
  pages={1--51},
  year={2016},
  url={https://www.jmlr.org/papers/v17/15-106.html}
}